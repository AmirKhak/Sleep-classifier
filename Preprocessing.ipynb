{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmFnBNoA32FO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e502c9f-b943-4897-8dcc-928df61c4479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_dir = '/content/gdrive/MyDrive/Data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "oaRNzUDhTwLR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "from time import sleep\n",
        "\n",
        "def PreprocessAWSFile(aws_file, sheet_name):\n",
        "  aws = pd.read_excel(aws_file, sheet_name=9)\n",
        "  aws = aws.drop(['Line', 'Epoch', 'Day', 'Seconds', 'Off-Wrist Status', 'Marker', \n",
        "                  'White Light', 'Red Light', 'Green Light', 'Blue Light', \n",
        "                  'Sleep/Wake', 'Mobility', 'Interval Status', 'S/W Status'], axis=1)\n",
        "\n",
        "  aws_complete_minute = pd.DataFrame(aws['Activity'])\n",
        "  aws_complete_minute['Label'] = aws.apply(\n",
        "      lambda x: str(x['Date'])[:10] + ' ' + x['Time'].strftime(\"%H:%M:%S\"), axis=1)\n",
        "\n",
        "  aws_complete_half_minute = pd.DataFrame({'Activity': [np.nan] * aws.shape[0]})\n",
        "  aws_complete_half_minute['Label'] = aws.apply(\n",
        "      lambda x: str(x['Date'])[:10] + ' ' + x['Time'].strftime(\"%H:%M\")+':30', axis=1)\n",
        "\n",
        "  aws = pd.concat([aws_complete_half_minute, aws_complete_minute]).sort_values(\n",
        "      by=['Label']).reset_index(drop=True)\n",
        "\n",
        "  aws['Activity'] = aws['Activity'].interpolate().replace(np.nan, 0)\n",
        "  return aws\n",
        "\n",
        "def PreprocessAX3File(ax3_file, chunks = 2):\n",
        "  ax3 = pd.read_csv(ax3_file, header=None, squeeze=True)\n",
        "  section_size = int(ax3.shape[0] / chunks)\n",
        "  for i in range(chunks):\n",
        "    ax3_processed_part = PreprocessAX3Data(ax3[i * section_size: section_size * (i + 1)])\n",
        "    ax3_processed_part.to_csv('part' + str(i+1) + '.csv', index=False)\n",
        "    ax3_processed_part = None\n",
        "    print(i+1)\n",
        "    sleep(40) # Waiting for RAM to get emptied\n",
        "  ax3 = None\n",
        "\n",
        "def GetProcessedAX3Data(chunks = 2):\n",
        "  ax3 = None\n",
        "  for i in range(chunks):\n",
        "    file_name = 'part' + str(i+1) + '.csv'\n",
        "    temp = pd.read_csv(file_name, squeeze=True, index_col=False)\n",
        "    ax3 = pd.concat([ax3, temp])\n",
        "    os.remove(file_name)\n",
        "    temp = 0\n",
        "  ax3 = ax3.reset_index()\n",
        "  return ax3\n",
        "\n",
        "def PreprocessAX3Data(ax3):\n",
        "  ax3.columns = (['Date_time', 'X', 'Y', 'Z', 'Light', 'Temp'])\n",
        "  ax3 = ax3.drop([\"Light\"], axis=1)\n",
        "  ax3 = ax3[:-1]\n",
        "\n",
        "  ax3['Label'] = ax3['Date_time'].map(lambda x : \n",
        "                x[0:17] + str(int(float(x[17:])>=30)*3) + \"0\")\n",
        "\n",
        "  ax3 = ax3.groupby(['Label']).agg({'X': lambda x : list(x), \n",
        "                                    'Y': lambda x : list(x), \n",
        "                                    'Z': lambda x : list(x), \n",
        "                                    'Temp': lambda x : list(x)}).reset_index()\n",
        "  \n",
        "  return ax3"
      ],
      "metadata": {
        "id": "MXFOn2nTTyB-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing AWS Data"
      ],
      "metadata": {
        "id": "jBZKZSSQj1Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws_file = os.path.join(root_dir, \"18 participants/AWS/SDRI001_AWS_ALL_ALLV4_N1.xlsx\")\n",
        "aws = PreprocessAWSFile(aws_file, 0)\n",
        "print(aws.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D11fa-evj7Rk",
        "outputId": "aa265875-1451-4891-84af-4de84a2c0f94"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Activity                Label\n",
            "0       0.0  2020-02-17 12:54:00\n",
            "1       0.0  2020-02-17 12:54:30\n",
            "2       0.0  2020-02-17 12:55:00\n",
            "3       0.0  2020-02-17 12:55:30\n",
            "4       0.0  2020-02-17 12:56:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing AX3 Data"
      ],
      "metadata": {
        "id": "-lf3-AwLjtTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax3_dir = os.path.join(root_dir, \"18 participants/AX3/Extracted\")\n",
        "psg_dir = os.path.join(root_dir, \"18 participants/PSG\")\n",
        "\n",
        "ax3_files = os.listdir(ax3_dir)\n",
        "psg_files = os.listdir(psg_dir)\n",
        "\n",
        "participant = 10\n",
        "\n",
        "print(ax3_files[0])\n",
        "ax3_file_part1 = os.path.join(ax3_dir, \"AX3_step1_sub17.csv\")\n",
        "#ax3_file_part2 = os.path.join(ax3_dir, \"AX3_step1_sub\" + str(participant) + \"_part2.csv\")\n",
        "\n",
        "#ax3 = None\n",
        "ax3_part1 = None\n",
        "#ax3_part2 = None\n",
        "\n",
        "ax3_part1 = PreprocessAX3File(ax3_file_part1)\n",
        "#ax3_part2 = PreprocessAX3File(ax3_file_part2)\n",
        "\n",
        "#ax3 = pd.concat([ax3_part1, ax3_part2]).reset_index()\n",
        "\n",
        "#print(ax3.columns)\n",
        "#print(ax3.head(5))\n",
        "#print(ax3.tail(1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETfw6xVMa5gK",
        "outputId": "a5b64234-3b7e-4519-e16f-3840f29430d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AX3_step1_sub18.csv\n",
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging AX3 and AWS Data"
      ],
      "metadata": {
        "id": "O8H44uCfj76T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax3.to_csv(\"AX3_step1_sub17.csv\", index=False)"
      ],
      "metadata": {
        "id": "4AYMuY1V_1PO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax3 = GetProcessedAX3Data(chunks = 2)\n",
        "\n",
        "print(ax3.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgTFJhALkA9s",
        "outputId": "6ae2f120-c44f-488b-d255-99392d1ce388"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Label', 'X', 'Y', 'Z', 'Temp'], dtype='object')\n"
          ]
        }
      ]
    }
  ]
}
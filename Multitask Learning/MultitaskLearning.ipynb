{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultitaskLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SiRGpvFwBRoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477da5d5-a4b4-4fde-9122-eb4dcdac0c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_dir = '/content/gdrive/MyDrive/Data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from pandas.core.frame import DataFrame\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "TIt0YKZACJzY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFfsn5AD4uys",
        "outputId": "678a7efe-8e3b-41ce-a277-f96932e66e44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experience = 1\n",
        "\n",
        "features_dir = os.path.join(root_dir, \"18 participants/AX3/TransformedData\" + str(experience))\n",
        "file_name = os.path.join(features_dir, \"Labelled\")\n",
        "\n",
        "def encode_sleep_stage(val):\n",
        "  arr = {'N1':0, 'N2':1, 'N3':2, 'REM':3, 'Wake':4, 'Artefact':np.NaN, 'A':np.NaN}\n",
        "  return arr[val]\n",
        "\n",
        "def encode_sleep_state(val):\n",
        "  arr = {'N1':0, 'N2':1, 'N3':2, 'REM':3, 'Wake':4, 'Artefact':np.NaN, 'A':np.NaN}\n",
        "  return arr[val]\n",
        "\n",
        "def plot_graph(x, y, z, x_label, y_label, legends, figsize=(7,7)):\n",
        "  plt.plot(z, x, 'r--')\n",
        "  plt.plot(z, y, 'b-')\n",
        "  plt.legend(legends)\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.show();\n",
        "\n",
        "dataset = pd.read_pickle(file_name)\n",
        "dataset['Sleep State'] = dataset['Sleep State'].apply(lambda x: encode_sleep_stage(x))\n",
        "dataset['Sleep State'] = pd.Series(np.array(dataset['Sleep State'])).interpolate()\n",
        "dataset['Sleep State'] = np.array(dataset['Sleep State'].replace(to_replace = np.nan, value=4), dtype=np.int64)\n",
        "\n",
        "n = dataset.shape[0]\n",
        "train_ratio = 0.9\n",
        "separate_id = int(n * train_ratio)\n",
        "\n",
        "labels = np.zeros((n,5))\n",
        "y_single = np.zeros((n,2))\n",
        "\n",
        "for i in range(n):\n",
        "  label = dataset.iloc[i]['Sleep State']\n",
        "  labels[i][label] = 1\n",
        "  if label < 4:\n",
        "    y_single[i][0] = 1\n",
        "  else:\n",
        "    y_single[i][1] = 1\n",
        "\n",
        "print(dataset['Sleep State'].value_counts())\n",
        "dataset = dataset.drop(['Label', 'Sleep State'], axis=1)\n",
        "dataset += 0.001\n",
        "dataset = np.array(dataset)\n",
        "\n",
        "dataset = dataset.reshape((dataset.shape[0], dataset.shape[1], 1, 1))\n",
        "\n",
        "x_train = dataset[:separate_id]\n",
        "y_train = labels[:separate_id]\n",
        "y_train_single = y_single[:separate_id]\n",
        "\n",
        "x_test = dataset[separate_id:]\n",
        "y_test = labels[separate_id:]\n",
        "y_test_single = y_single[separate_id:]\n",
        "\n",
        "print(dataset.shape)\n",
        "#print(dataset[0])\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1UKlUX7xW6H",
        "outputId": "bef6a04d-414e-469d-b97d-83a483b86c56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    6536\n",
            "4    5670\n",
            "2    2740\n",
            "0    2140\n",
            "3    2123\n",
            "Name: Sleep State, dtype: int64\n",
            "(19209, 24, 1, 1)\n",
            "(19209, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Activation, MaxPool2D, Flatten, Add, Dense\n",
        "\n",
        "input_ = Input(shape=(dataset.shape[1],1,1), name='input')\n",
        "\n",
        "conv_1 = Conv2D(24, 1, name='conv_1')(input_)\n",
        "act_1 = Activation('relu', name='act_1')(conv_1)\n",
        "\n",
        "conv_2 = Conv2D(16, 1, name='conv_2')(act_1)\n",
        "act_2 = Activation('relu', name='act_2')(conv_2)\n",
        "\n",
        "flat_1 = Flatten(name='flat_1')(act_2)\n",
        "\n",
        "task_1_dense_1 = Dense(10, activation='sigmoid', name='task_1_dense_1')(flat_1)\n",
        "task_1_dense_2 = Dense(5, activation='softmax', name='task_1_dense_2')(task_1_dense_1)\n",
        "\n",
        "task_2_dense_1 = Dense(10, activation='sigmoid', name='task_2_dense_1')(flat_1)\n",
        "task_2_dense_2 = Dense(2, activation='softmax', name='task_2_dense_2')(task_2_dense_1)\n",
        "\n",
        "model = tf.keras.models.Model(input_, [task_1_dense_2, task_2_dense_2])\n",
        "\n",
        "model.compile(\n",
        "    loss={\n",
        "        'task_1_dense_2': 'categorical_crossentropy',\n",
        "        'task_2_dense_2': 'binary_crossentropy'\n",
        "    },\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "_ = model.fit(x_train, [y_train, y_train_single], validation_data=(x_test, [y_test, y_test_single]), \n",
        "              epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "AH9XdQGSYmtt",
        "outputId": "4fd678f7-05a6-4d61-8ef6-6617e88da666"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3ff086b9f170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    }
  ]
}